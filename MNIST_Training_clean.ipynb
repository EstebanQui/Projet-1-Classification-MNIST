{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6794ab4",
   "metadata": {},
   "source": [
    "# MNIST Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9372de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import gzip\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Configuration du style matplotlib\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Configuration PyTorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)  # Pour la reproductibilit√©\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Configuration du syst√®me\")\n",
    "print(f\"Device utilis√©: {device}\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"NumPy version: {np.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"M√©moire GPU disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"GPU non disponible, utilisation du CPU\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c61b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Architecture CNN pour la classification MNIST\n",
    "    \n",
    "    Structure:\n",
    "    - Conv2D(1‚Üí32) + ReLU + MaxPool2D\n",
    "    - Conv2D(32‚Üí64) + ReLU + MaxPool2D  \n",
    "    - Conv2D(64‚Üí128) + ReLU + MaxPool2D\n",
    "    - Flatten + FC(1152‚Üí512) + ReLU + Dropout(0.5)\n",
    "    - FC(512‚Üí256) + ReLU + Dropout(0.5)\n",
    "    - FC(256‚Üí10) [Sortie - 10 classes]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        \n",
    "        # Couches convolutionnelles\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)    # 28x28 ‚Üí 28x28\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)   # 14x14 ‚Üí 14x14  \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 7x7 ‚Üí 7x7\n",
    "        \n",
    "        # MaxPooling 2x2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Couches fully connected\n",
    "        # Apr√®s 3x MaxPool2D: 28‚Üí14‚Üí7‚Üí3, donc 3x3x128 = 1152\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)  # 10 classes (chiffres 0-9)\n",
    "        \n",
    "        # Dropout pour r√©gularisation\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Bloc convolutionnel 1: Conv ‚Üí ReLU ‚Üí MaxPool\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (B, 1, 28, 28) ‚Üí (B, 32, 14, 14)\n",
    "        \n",
    "        # Bloc convolutionnel 2\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (B, 32, 14, 14) ‚Üí (B, 64, 7, 7)\n",
    "        \n",
    "        # Bloc convolutionnel 3  \n",
    "        x = self.pool(F.relu(self.conv3(x)))  # (B, 64, 7, 7) ‚Üí (B, 128, 3, 3)\n",
    "        \n",
    "        # Aplatir pour les couches FC\n",
    "        x = x.view(-1, 128 * 3 * 3)  # (B, 128, 3, 3) ‚Üí (B, 1152)\n",
    "        \n",
    "        # Couches fully connected avec dropout\n",
    "        x = F.relu(self.fc1(x))      # (B, 1152) ‚Üí (B, 512)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))      # (B, 512) ‚Üí (B, 256)  \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)              # (B, 256) ‚Üí (B, 10)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        \"\"\"Compte le nombre de param√®tres du mod√®le\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "# Cr√©er une instance du mod√®le pour tester\n",
    "model = MNISTNet().to(device)\n",
    "print(f\"Mod√®le CNN cr√©√© avec {model.count_parameters():,} param√®tres\")\n",
    "\n",
    "# Tester avec un exemple d'entr√©e\n",
    "example_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "with torch.no_grad():\n",
    "    example_output = model(example_input)\n",
    "    print(f\"Test forward pass: {example_input.shape} ‚Üí {example_output.shape}\")\n",
    "    print(f\"Exemple de sortie: {example_output.squeeze()[:5].cpu().numpy()}\")  # Premi√®res 5 valeurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326304c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist():\n",
    "    \"\"\"\n",
    "    T√©l√©charge et charge les donn√©es MNIST depuis les serveurs PyTorch officiels\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_images, train_labels, test_images, test_labels)\n",
    "    \"\"\"\n",
    "    \n",
    "    # URLs des serveurs PyTorch\n",
    "    urls = {\n",
    "        'train-images-idx3-ubyte.gz': 'https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz',\n",
    "        'train-labels-idx1-ubyte.gz': 'https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz',\n",
    "        't10k-images-idx3-ubyte.gz': 'https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz',\n",
    "        't10k-labels-idx1-ubyte.gz': 'https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "    }\n",
    "    \n",
    "    data_dir = 'data'\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    def load_images(filename):\n",
    "        \"\"\"Charge les images depuis un fichier .gz\"\"\"\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        \n",
    "        # T√©l√©charger si n√©cessaire\n",
    "        if not os.path.exists(filepath):\n",
    "            url = urls[filename]\n",
    "            print(f\"T√©l√©chargement: {filename}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"T√©l√©charg√©: {os.path.getsize(filepath) / 1e6:.1f} MB\")\n",
    "        \n",
    "        # Lire le fichier binaire\n",
    "        with gzip.open(filepath, 'rb') as f:\n",
    "            data = f.read()\n",
    "            magic = int.from_bytes(data[0:4], 'big')\n",
    "            num_images = int.from_bytes(data[4:8], 'big')\n",
    "            rows = int.from_bytes(data[8:12], 'big')\n",
    "            cols = int.from_bytes(data[12:16], 'big')\n",
    "            \n",
    "            images = np.frombuffer(data[16:], dtype=np.uint8)\n",
    "            images = images.reshape(num_images, rows, cols)\n",
    "            return images\n",
    "    \n",
    "    def load_labels(filename):\n",
    "        \"\"\"Charge les labels depuis un fichier .gz\"\"\"\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        \n",
    "        # T√©l√©charger si n√©cessaire\n",
    "        if not os.path.exists(filepath):\n",
    "            url = urls[filename]\n",
    "            print(f\" T√©l√©chargement: {filename}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"T√©l√©charg√©: {os.path.getsize(filepath) / 1e3:.1f} KB\")\n",
    "        \n",
    "        # Lire le fichier binaire\n",
    "        with gzip.open(filepath, 'rb') as f:\n",
    "            data = f.read()\n",
    "            magic = int.from_bytes(data[0:4], 'big')\n",
    "            num_labels = int.from_bytes(data[4:8], 'big')\n",
    "            labels = np.frombuffer(data[8:], dtype=np.uint8)\n",
    "            return labels\n",
    "    \n",
    "    print(\"Chargement des donn√©es MNIST...\")\n",
    "    \n",
    "    # Charger tous les fichiers\n",
    "    train_images = load_images('train-images-idx3-ubyte.gz')\n",
    "    train_labels = load_labels('train-labels-idx1-ubyte.gz')\n",
    "    test_images = load_images('t10k-images-idx3-ubyte.gz')\n",
    "    test_labels = load_labels('t10k-labels-idx1-ubyte.gz')\n",
    "    \n",
    "    print(f\"Dataset charg√©:\")\n",
    "    print(f\"Training: {train_images.shape[0]:,} images ({train_images.shape[1]}x{train_images.shape[2]})\")\n",
    "    print(f\"Test: {test_images.shape[0]:,} images ({test_images.shape[1]}x{test_images.shape[2]})\")\n",
    "    print(f\"Classes: {len(np.unique(train_labels))} (chiffres 0-9)\")\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "# Charger les donn√©es\n",
    "train_images, train_labels, test_images, test_labels = download_mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de quelques exemples avant pr√©processing\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "fig.suptitle('Exemples d\\'images MNIST (avant pr√©processing)', fontsize=14, y=1.02)\n",
    "\n",
    "for i in range(10):\n",
    "    row, col = i // 5, i % 5\n",
    "    axes[row, col].imshow(train_images[i], cmap='gray')\n",
    "    axes[row, col].set_title(f'Label: {train_labels[i]}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques des donn√©es brutes\n",
    "print(\"Statistiques des donn√©es brutes:\")\n",
    "print(f\"Valeurs pixels: [{train_images.min()}, {train_images.max()}]\")\n",
    "print(f\"Moyenne: {train_images.mean():.3f}\")\n",
    "print(f\"√âcart-type: {train_images.std():.3f}\")\n",
    "print(f\"Distribution labels: {np.bincount(train_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_onnx(model, onnx_path='models/mnist_model.onnx'):\n",
    "    \"\"\"\n",
    "    Exporte le mod√®le PyTorch vers le format ONNX\n",
    "    \n",
    "    Args:\n",
    "        model: Mod√®le PyTorch entra√Æn√©\n",
    "        onnx_path: Chemin de sauvegarde du mod√®le ONNX\n",
    "    \n",
    "    Returns:\n",
    "        bool: True si l'export a r√©ussi\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Export du mod√®le vers ONNX...\")\n",
    "    \n",
    "    # Mettre le mod√®le en mode √©valuation\n",
    "    model.eval()\n",
    "    \n",
    "    # Cr√©er un exemple d'entr√©e pour l'export\n",
    "    example_input = torch.randn(1, 1, 28, 28, dtype=torch.float32).to(device)\n",
    "    \n",
    "    try:\n",
    "        # Export ONNX avec configuration optimis√©e pour le web\n",
    "        torch.onnx.export(\n",
    "            model,                      # Mod√®le PyTorch\n",
    "            example_input,              # Exemple d'entr√©e\n",
    "            onnx_path,                  # Chemin de sortie\n",
    "            export_params=True,         # Exporter les param√®tres du mod√®le\n",
    "            opset_version=11,           # Version ONNX (compatible navigateurs)\n",
    "            do_constant_folding=True,   # Optimisation des constantes\n",
    "            input_names=['input'],      # Nom de l'entr√©e\n",
    "            output_names=['output'],    # Nom de la sortie\n",
    "            dynamic_axes={              # Dimensions dynamiques pour batch variable\n",
    "                'input': {0: 'batch_size'},\n",
    "                'output': {0: 'batch_size'}\n",
    "            },\n",
    "            verbose=False               # Pas de logs verbeux\n",
    "        )\n",
    "        \n",
    "        # V√©rification de la taille du fichier\n",
    "        if os.path.exists(onnx_path):\n",
    "            size_mb = os.path.getsize(onnx_path) / (1024 * 1024)\n",
    "            print(f\"Export ONNX r√©ussi!\")\n",
    "            print(f\"Fichier: {onnx_path}\")\n",
    "            print(f\"Taille: {size_mb:.1f} MB\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"Erreur: Fichier ONNX non cr√©√©\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de l'export ONNX: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_onnx_inference(onnx_path, num_samples=5):\n",
    "    \"\"\"\n",
    "    Test l'inf√©rence ONNX et compare avec PyTorch\n",
    "    \n",
    "    Args:\n",
    "        onnx_path: Chemin du mod√®le ONNX\n",
    "        num_samples: Nombre d'√©chantillons √† tester\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        import onnxruntime\n",
    "        print(\"Test de l'inf√©rence ONNX...\")\n",
    "        \n",
    "        # Cr√©er la session ONNX Runtime\n",
    "        ort_session = onnxruntime.InferenceSession(\n",
    "            onnx_path,\n",
    "            providers=['CPUExecutionProvider']  # CPU uniquement pour la compatibilit√© web\n",
    "        )\n",
    "        \n",
    "        # Obtenir quelques √©chantillons du dataset de test\n",
    "        sample_data = []\n",
    "        sample_labels = []\n",
    "        \n",
    "        for i, (data, label) in enumerate(test_loader):\n",
    "            if i * BATCH_SIZE >= num_samples:\n",
    "                break\n",
    "            sample_data.append(data[:num_samples - len(sample_data)])\n",
    "            sample_labels.extend(label[:num_samples - len(sample_labels)])\n",
    "        \n",
    "        sample_data = torch.cat(sample_data)[:num_samples]\n",
    "        sample_labels = sample_labels[:num_samples]\n",
    "        \n",
    "        # Pr√©dictions PyTorch\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pytorch_outputs = model(sample_data.to(device))\n",
    "            pytorch_preds = torch.argmax(pytorch_outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        # Pr√©dictions ONNX\n",
    "        onnx_inputs = sample_data.cpu().numpy()\n",
    "        onnx_outputs = ort_session.run(None, {'input': onnx_inputs})[0]\n",
    "        onnx_preds = np.argmax(onnx_outputs, axis=1)\n",
    "        \n",
    "        # Comparaison des r√©sultats\n",
    "        matches = np.sum(pytorch_preds == onnx_preds)\n",
    "        print(f\"Concordance PyTorch-ONNX: {matches}/{num_samples} ({100*matches/num_samples:.1f}%)\")\n",
    "        \n",
    "        # Afficher quelques exemples\n",
    "        print(\"Exemples de pr√©dictions:\")\n",
    "        for i in range(min(3, num_samples)):\n",
    "            true_label = sample_labels[i]\n",
    "            pytorch_pred = pytorch_preds[i]\n",
    "            onnx_pred = onnx_preds[i]\n",
    "            match = \"Oui\" if pytorch_pred == onnx_pred else \"Non\"\n",
    "            print(f\"   √âchantillon {i+1}: Vrai={true_label} | PyTorch={pytorch_pred} | ONNX={onnx_pred} {match}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\" onnxruntime non install√© - Test d'inf√©rence ignor√©\")\n",
    "        print(\"   Installation: pip install onnxruntime\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du test ONNX: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"EXPORT ONNX\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Export du mod√®le vers ONNX\n",
    "success = export_to_onnx(model)\n",
    "\n",
    "if success:\n",
    "    # Test de l'inf√©rence ONNX\n",
    "    test_onnx_inference('models/mnist_model.onnx')\n",
    "    \n",
    "    # Copier vers le dossier web\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.copy('models/mnist_model.onnx', 'web/mnist_model.onnx')\n",
    "        print(\"Mod√®le ONNX copi√© vers web/mnist_model.onnx\")\n",
    "        print(\"Pr√™t pour l'interface web!\")\n",
    "    except Exception as e:\n",
    "        print(f\" Erreur lors de la copie: {e}\")\n",
    "    \n",
    "    print(\"PROJET MNIST TERMIN√â AVEC SUCC√àS!\")\n",
    "    print(\"Fichiers g√©n√©r√©s:\")\n",
    "    print(\"models/mnist_model_best.pth - Mod√®le PyTorch\")\n",
    "    print(\"models/mnist_model.onnx - Mod√®le ONNX\")\n",
    "    print(\"web/mnist_model.onnx - Pr√™t pour le web\")\n",
    "else:\n",
    "    print(\"Export ONNX √©chou√© - V√©rifiez les erreurs ci-dessus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c2b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(images, labels):\n",
    "    \"\"\"\n",
    "    Pr√©processing des donn√©es MNIST selon les standards\n",
    "    \n",
    "    Args:\n",
    "        images: numpy array de forme (N, 28, 28)\n",
    "        labels: numpy array de forme (N,)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (images_tensor, labels_tensor) normalis√©s\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Conversion en float32 et normalisation [0,255] ‚Üí [0,1]\n",
    "    images = images.astype(np.float32) / 255.0\n",
    "    \n",
    "    # 2. Standardisation MNIST (calcul√©e sur l'ensemble du dataset)\n",
    "    mean = 0.1307  # Moyenne officielle MNIST\n",
    "    std = 0.3081   # √âcart-type officiel MNIST\n",
    "    images = (images - mean) / std\n",
    "    \n",
    "    # 3. Ajouter la dimension canal: (28, 28) ‚Üí (1, 28, 28)\n",
    "    images = images[:, np.newaxis, :, :]\n",
    "    \n",
    "    # 4. Conversion en tenseurs PyTorch\n",
    "    images_tensor = torch.from_numpy(images)\n",
    "    labels_tensor = torch.from_numpy(labels.astype(np.int64))\n",
    "    \n",
    "    return images_tensor, labels_tensor\n",
    "\n",
    "def create_data_loaders(batch_size=64):\n",
    "    \"\"\"\n",
    "    Cr√©e les DataLoaders PyTorch pour l'entra√Ænement\n",
    "    \n",
    "    Args:\n",
    "        batch_size: Taille des batches\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (train_loader, test_loader)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"Pr√©processing des donn√©es...\")\n",
    "    \n",
    "    # Pr√©processing\n",
    "    train_images_tensor, train_labels_tensor = preprocess_data(train_images, train_labels)\n",
    "    test_images_tensor, test_labels_tensor = preprocess_data(test_images, test_labels)\n",
    "    \n",
    "    # Cr√©er les datasets PyTorch\n",
    "    train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "    test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "    \n",
    "    # Cr√©er les DataLoaders avec m√©lange pour l'entra√Ænement\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(f\"DataLoaders cr√©√©s:\")\n",
    "    print(f\"   Training: {len(train_loader)} batches de {batch_size} images\")\n",
    "    print(f\"   Test: {len(test_loader)} batches de {batch_size} images\")\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Cr√©er les DataLoaders\n",
    "BATCH_SIZE = 128  # Batch size optimal pour MNIST\n",
    "train_loader, test_loader = create_data_loaders(BATCH_SIZE)\n",
    "\n",
    "# V√©rifier un batch d'exemple\n",
    "sample_batch = next(iter(train_loader))\n",
    "sample_images, sample_labels = sample_batch\n",
    "print(f\"Exemple de batch:\")\n",
    "print(f\"Images: {sample_images.shape} (batch, canal, hauteur, largeur)\")\n",
    "print(f\"Labels: {sample_labels.shape}\")\n",
    "print(f\"Plage valeurs: [{sample_images.min():.3f}, {sample_images.max():.3f}]\")\n",
    "print(f\"Labels exemple: {sample_labels[:10].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b79548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch_num):\n",
    "    \"\"\"\n",
    "    Entra√Æne le mod√®le pour une √©poque\n",
    "    \n",
    "    Args:\n",
    "        model: Mod√®le PyTorch\n",
    "        train_loader: DataLoader d'entra√Ænement\n",
    "        criterion: Fonction de perte\n",
    "        optimizer: Optimiseur\n",
    "        device: Device (cpu/cuda)\n",
    "        epoch_num: Num√©ro de l'√©poque actuelle\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (loss_moyenne, accuracy_pourcentage)\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()  # Mode entra√Ænement\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Barre de progression\n",
    "    batch_count = 0\n",
    "    print_interval = len(train_loader) // 10  # Affichage 10 fois par √©poque\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # D√©placer sur le device\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistiques\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Affichage du progr√®s\n",
    "        if batch_idx % print_interval == 0 and batch_idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            current_acc = 100. * correct / total\n",
    "            print(f'√âpoque {epoch_num} | Batch {batch_idx:3d}/{len(train_loader)} | '\n",
    "                  f'Loss: {loss.item():.4f} | Acc: {current_acc:.2f}% | '\n",
    "                  f'Temps: {elapsed:.1f}s')\n",
    "    \n",
    "    # R√©sultats finaux de l'√©poque\n",
    "    final_loss = running_loss / len(train_loader)\n",
    "    final_accuracy = 100. * correct / total\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    print(f'√âpoque {epoch_num} termin√©e - Loss: {final_loss:.4f} | '\n",
    "          f'Accuracy: {final_accuracy:.2f}% | Temps: {epoch_time:.1f}s')\n",
    "    \n",
    "    return final_loss, final_accuracy\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    √âvalue le mod√®le sur le dataset de test\n",
    "    \n",
    "    Args:\n",
    "        model: Mod√®le PyTorch  \n",
    "        test_loader: DataLoader de test\n",
    "        criterion: Fonction de perte\n",
    "        device: Device (cpu/cuda)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (loss_moyenne, accuracy_pourcentage)\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()  # Mode √©valuation\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Pas de gradient pour l'√©valuation\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    final_loss = test_loss / len(test_loader)\n",
    "    final_accuracy = 100. * correct / total\n",
    "    \n",
    "    return final_loss, final_accuracy\n",
    "\n",
    "def save_model(model, optimizer, epoch, loss, accuracy, filepath):\n",
    "    \"\"\"\n",
    "    Sauvegarde le mod√®le avec m√©tadonn√©es\n",
    "    \n",
    "    Args:\n",
    "        model: Mod√®le PyTorch\n",
    "        optimizer: Optimiseur\n",
    "        epoch: Num√©ro d'√©poque\n",
    "        loss: Loss actuelle\n",
    "        accuracy: Accuracy actuelle  \n",
    "        filepath: Chemin de sauvegarde\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'model_architecture': 'MNISTNet CNN'\n",
    "    }, filepath)\n",
    "    \n",
    "    print(f\"Mod√®le sauvegard√©: {filepath}\")\n",
    "\n",
    "print(\"Fonctions d'entra√Ænement d√©finies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31811ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam√®tres d'entra√Ænement\n",
    "NUM_EPOCHS = 10  # Augment√© pour une meilleure pr√©cision\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(\"D√©but de l'entra√Ænement MNIST\")\n",
    "print(f\"Configuration:\")\n",
    "print(f\"√âpoques: {NUM_EPOCHS}\")\n",
    "print(f\"Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"Batch size: {BATCH_SIZE}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialisation du mod√®le et des composants d'entra√Ænement\n",
    "model = MNISTNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Variables pour suivre le meilleur mod√®le\n",
    "best_accuracy = 0.0\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Boucle d'entra√Ænement principale\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\\\n=== √âPOQUE {epoch}/{NUM_EPOCHS} ===\")\n",
    "    \n",
    "    # Entra√Ænement sur une √©poque\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    \n",
    "    # √âvaluation sur le dataset de test\n",
    "    print(\"√âvaluation sur le dataset de test...\")\n",
    "    test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Enregistrer les m√©triques\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    # Affichage des r√©sultats de l'√©poque\n",
    "    print(f\"R√©sultats √âpoque {epoch}:\")\n",
    "    print(f\"Train - Loss: {train_loss:.4f} | Accuracy: {train_acc:.2f}%\")\n",
    "    print(f\"Test  - Loss: {test_loss:.4f} | Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    # Sauvegarder le meilleur mod√®le\n",
    "    if test_acc > best_accuracy:\n",
    "        best_accuracy = test_acc\n",
    "        save_model(model, optimizer, epoch, test_loss, test_acc, 'models/mnist_model_best.pth')\n",
    "        print(f\"Nouveau meilleur mod√®le! Accuracy: {best_accuracy:.2f}%\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Statistiques finales\n",
    "total_time = time.time() - total_start_time\n",
    "print(f\"ENTRA√éNEMENT TERMIN√â!\")\n",
    "print(f\"Temps total: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "print(f\"Meilleure accuracy: {best_accuracy:.2f}%\")\n",
    "print(f\"Am√©lioration: {test_accuracies[-1] - test_accuracies[0]:.2f}% points\")\n",
    "\n",
    "# Sauvegarder le mod√®le final\n",
    "save_model(model, optimizer, NUM_EPOCHS, test_losses[-1], test_accuracies[-1], 'models/mnist_model_final.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphiques de performance\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('R√©sultats d\\'entra√Ænement MNIST CNN', fontsize=16, y=0.98)\n",
    "\n",
    "epochs = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "# Graphique 1: Loss d'entra√Ænement et de test\n",
    "ax1.plot(epochs, train_losses, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "ax1.plot(epochs, test_losses, 'r-o', label='Test Loss', linewidth=2, markersize=6)\n",
    "ax1.set_title('√âvolution de la Loss', fontsize=14)\n",
    "ax1.set_xlabel('√âpoque')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 2: Accuracy d'entra√Ænement et de test\n",
    "ax2.plot(epochs, train_accuracies, 'b-o', label='Training Accuracy', linewidth=2, markersize=6)\n",
    "ax2.plot(epochs, test_accuracies, 'r-o', label='Test Accuracy', linewidth=2, markersize=6)\n",
    "ax2.set_title('√âvolution de l\\'Accuracy', fontsize=14)\n",
    "ax2.set_xlabel('√âpoque')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(80, 100)\n",
    "\n",
    "# Graphique 3: Comparaison Train vs Test Accuracy\n",
    "ax3.scatter(train_accuracies, test_accuracies, c=epochs, cmap='viridis', s=100, alpha=0.7)\n",
    "ax3.plot([80, 100], [80, 100], 'k--', alpha=0.5, label='Train = Test')\n",
    "ax3.set_title('Train vs Test Accuracy', fontsize=14)\n",
    "ax3.set_xlabel('Training Accuracy (%)')\n",
    "ax3.set_ylabel('Test Accuracy (%)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_xlim(80, 100)\n",
    "ax3.set_ylim(80, 100)\n",
    "\n",
    "# Graphique 4: M√©triques finales\n",
    "metrics = ['Train Loss', 'Test Loss', 'Train Acc', 'Test Acc']\n",
    "values = [train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]]\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold']\n",
    "\n",
    "bars = ax4.bar(metrics, values, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax4.set_title('M√©triques finales', fontsize=14)\n",
    "ax4.set_ylabel('Valeur')\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar, value in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{value:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# R√©sum√© statistique\n",
    "print(\"R√âSUM√â DES PERFORMANCES:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Accuracy finale: {test_accuracies[-1]:.2f}%\")\n",
    "print(f\"Meilleure accuracy: {best_accuracy:.2f}%\")\n",
    "print(f\"Am√©lioration totale: {test_accuracies[-1] - test_accuracies[0]:.2f}% points\")\n",
    "print(f\"Loss finale: {test_losses[-1]:.4f}\")\n",
    "print(f\"√âcart Train-Test: {abs(train_accuracies[-1] - test_accuracies[-1]):.2f}% points\")\n",
    "\n",
    "if abs(train_accuracies[-1] - test_accuracies[-1]) < 5:\n",
    "    print(\"Pas de surapprentissage d√©tect√©\")\n",
    "else:\n",
    "    print(\" Possible surapprentissage\")\n",
    "\n",
    "if test_accuracies[-1] > 95:\n",
    "    print(\"Objectif de >95% atteint!\")\n",
    "else:\n",
    "    print(f\"Objectif: atteindre >95% (actuel: {test_accuracies[-1]:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b470cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import threading\n",
    "import socket\n",
    "from IPython.display import HTML, display\n",
    "import webbrowser\n",
    "\n",
    "def check_port_available(port):\n",
    "    \"\"\"V√©rifie si un port est disponible\"\"\"\n",
    "    try:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            return s.connect_ex(('localhost', port)) != 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def start_web_server(port=8000):\n",
    "    \"\"\"Lance le serveur web depuis le dossier web (chemin correct)\"\"\"\n",
    "    \n",
    "    # V√©rifier que le port est libre\n",
    "    original_port = port\n",
    "    while not check_port_available(port):\n",
    "        port += 1\n",
    "        if port > original_port + 10:\n",
    "            print(f\"Impossible de trouver un port libre (test√© {original_port}-{port})\")\n",
    "            return None\n",
    "    \n",
    "    # V√©rifier que le dossier web et le mod√®le existent\n",
    "    web_dir = 'web'\n",
    "    model_file = os.path.join(web_dir, 'mnist_model.onnx')\n",
    "    \n",
    "    if not os.path.exists(web_dir):\n",
    "        print(f\"Dossier {web_dir} introuvable\")\n",
    "        return None\n",
    "        \n",
    "    if not os.path.exists(model_file):\n",
    "        print(f\"Mod√®le ONNX introuvable: {model_file}\")\n",
    "        print(\"   Ex√©cutez d'abord la cellule d'export ONNX\")\n",
    "        return None\n",
    "    \n",
    "    def run_server():\n",
    "        try:\n",
    "            # Lancer le serveur depuis le dossier web\n",
    "            subprocess.run(['python', '-m', 'http.server', str(port)],\n",
    "                         stdout=subprocess.DEVNULL,\n",
    "                         stderr=subprocess.DEVNULL,\n",
    "                         cwd=web_dir)  # Ex√©cuter depuis le dossier web\n",
    "        except Exception as e:\n",
    "            print(f\"Erreur serveur: {e}\")\n",
    "\n",
    "    server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "    server_thread.start()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # URLs corrig√©es\n",
    "    local_url = f\"http://localhost:{port}/\"\n",
    "    network_url = f\"http://127.0.0.1:{port}/\"\n",
    "\n",
    "    print(\"Serveur web d√©marr√© avec succ√®s!\")\n",
    "    print(f\"Acc√®s local: {local_url}\")\n",
    "    print(f\"Acc√®s r√©seau: {network_url}\")\n",
    "    \n",
    "    # Cr√©er un lien cliquable\n",
    "    display(HTML(f'''\n",
    "    <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                padding: 20px; border-radius: 10px; text-align: center; margin: 20px 0;\">\n",
    "        <h2 style=\"color: white; margin-bottom: 15px;\">üåê Interface Web MNIST</h2>\n",
    "        <a href=\"{local_url}\" target=\"_blank\" \n",
    "           style=\"background: white; color: #667eea; padding: 15px 30px; \n",
    "                  border-radius: 25px; text-decoration: none; font-weight: bold;\n",
    "                  box-shadow: 0 4px 15px rgba(0,0,0,0.2); font-size: 18px;\">\n",
    "            Ouvrir l'Interface MNIST\n",
    "        </a>\n",
    "        <p style=\"color: white; margin-top: 15px; font-size: 14px;\">\n",
    "            Dessinez un chiffre et obtenez une pr√©diction instantan√©e !\n",
    "        </p>\n",
    "    </div>\n",
    "    '''))\n",
    "    \n",
    "    return port\n",
    "\n",
    "print(\"LANCEMENT DE L'INTERFACE WEB\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "server_port = start_web_server()\n",
    "\n",
    "if server_port:\n",
    "    print(f\"Interface web active sur le port {server_port}\")\n",
    "else:\n",
    "    print(\"Erreur lors du lancement de l'interface web\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
