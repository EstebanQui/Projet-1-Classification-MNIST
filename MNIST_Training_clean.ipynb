{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6794ab4",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9372de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import gzip\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Configuration du style matplotlib\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Configuration PyTorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)  # Pour la reproductibilit√©\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"üîß Configuration du syst√®me\")\n",
    "print(f\"‚úÖ Device utilis√©: {device}\")\n",
    "print(f\"‚úÖ PyTorch version: {torch.__version__}\")\n",
    "print(f\"‚úÖ NumPy version: {np.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"‚úÖ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"‚úÖ CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"‚úÖ M√©moire GPU disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  GPU non disponible, utilisation du CPU\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c61b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Architecture CNN pour la classification MNIST\n",
    "    \n",
    "    Structure:\n",
    "    - Conv2D(1‚Üí32) + ReLU + MaxPool2D\n",
    "    - Conv2D(32‚Üí64) + ReLU + MaxPool2D  \n",
    "    - Conv2D(64‚Üí128) + ReLU + MaxPool2D\n",
    "    - Flatten + FC(1152‚Üí512) + ReLU + Dropout(0.5)\n",
    "    - FC(512‚Üí256) + ReLU + Dropout(0.5)\n",
    "    - FC(256‚Üí10) [Sortie - 10 classes]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        \n",
    "        # Couches convolutionnelles\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)    # 28x28 ‚Üí 28x28\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)   # 14x14 ‚Üí 14x14  \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 7x7 ‚Üí 7x7\n",
    "        \n",
    "        # MaxPooling 2x2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Couches fully connected\n",
    "        # Apr√®s 3x MaxPool2D: 28‚Üí14‚Üí7‚Üí3, donc 3x3x128 = 1152\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)  # 10 classes (chiffres 0-9)\n",
    "        \n",
    "        # Dropout pour r√©gularisation\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Bloc convolutionnel 1: Conv ‚Üí ReLU ‚Üí MaxPool\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (B, 1, 28, 28) ‚Üí (B, 32, 14, 14)\n",
    "        \n",
    "        # Bloc convolutionnel 2\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (B, 32, 14, 14) ‚Üí (B, 64, 7, 7)\n",
    "        \n",
    "        # Bloc convolutionnel 3  \n",
    "        x = self.pool(F.relu(self.conv3(x)))  # (B, 64, 7, 7) ‚Üí (B, 128, 3, 3)\n",
    "        \n",
    "        # Aplatir pour les couches FC\n",
    "        x = x.view(-1, 128 * 3 * 3)  # (B, 128, 3, 3) ‚Üí (B, 1152)\n",
    "        \n",
    "        # Couches fully connected avec dropout\n",
    "        x = F.relu(self.fc1(x))      # (B, 1152) ‚Üí (B, 512)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))      # (B, 512) ‚Üí (B, 256)  \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)              # (B, 256) ‚Üí (B, 10)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        \"\"\"Compte le nombre de param√®tres du mod√®le\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "# Cr√©er une instance du mod√®le pour tester\n",
    "model = MNISTNet().to(device)\n",
    "print(f\"üß† Mod√®le CNN cr√©√© avec {model.count_parameters():,} param√®tres\")\n",
    "\n",
    "# Tester avec un exemple d'entr√©e\n",
    "example_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "with torch.no_grad():\n",
    "    example_output = model(example_input)\n",
    "    print(f\"‚úÖ Test forward pass: {example_input.shape} ‚Üí {example_output.shape}\")\n",
    "    print(f\"‚úÖ Exemple de sortie: {example_output.squeeze()[:5].cpu().numpy()}\")  # Premi√®res 5 valeurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326304c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist():\n",
    "    \"\"\"\n",
    "    T√©l√©charge et charge les donn√©es MNIST depuis les serveurs PyTorch officiels\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_images, train_labels, test_images, test_labels)\n",
    "    \"\"\"\n",
    "    \n",
    "    # URLs des serveurs PyTorch (plus fiables que le site original)\n",
    "    urls = {\n",
    "        'train-images-idx3-ubyte.gz': 'https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz',\n",
    "        'train-labels-idx1-ubyte.gz': 'https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz',\n",
    "        't10k-images-idx3-ubyte.gz': 'https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz',\n",
    "        't10k-labels-idx1-ubyte.gz': 'https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "    }\n",
    "    \n",
    "    data_dir = 'data'\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    def load_images(filename):\n",
    "        \"\"\"Charge les images depuis un fichier .gz\"\"\"\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        \n",
    "        # T√©l√©charger si n√©cessaire\n",
    "        if not os.path.exists(filepath):\n",
    "            url = urls[filename]\n",
    "            print(f\"üì• T√©l√©chargement: {filename}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"‚úÖ T√©l√©charg√©: {os.path.getsize(filepath) / 1e6:.1f} MB\")\n",
    "        \n",
    "        # Lire le fichier binaire\n",
    "        with gzip.open(filepath, 'rb') as f:\n",
    "            data = f.read()\n",
    "            magic = int.from_bytes(data[0:4], 'big')\n",
    "            num_images = int.from_bytes(data[4:8], 'big')\n",
    "            rows = int.from_bytes(data[8:12], 'big')\n",
    "            cols = int.from_bytes(data[12:16], 'big')\n",
    "            \n",
    "            images = np.frombuffer(data[16:], dtype=np.uint8)\n",
    "            images = images.reshape(num_images, rows, cols)\n",
    "            return images\n",
    "    \n",
    "    def load_labels(filename):\n",
    "        \"\"\"Charge les labels depuis un fichier .gz\"\"\"\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        \n",
    "        # T√©l√©charger si n√©cessaire\n",
    "        if not os.path.exists(filepath):\n",
    "            url = urls[filename]\n",
    "            print(f\"üì• T√©l√©chargement: {filename}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"‚úÖ T√©l√©charg√©: {os.path.getsize(filepath) / 1e3:.1f} KB\")\n",
    "        \n",
    "        # Lire le fichier binaire\n",
    "        with gzip.open(filepath, 'rb') as f:\n",
    "            data = f.read()\n",
    "            magic = int.from_bytes(data[0:4], 'big')\n",
    "            num_labels = int.from_bytes(data[4:8], 'big')\n",
    "            labels = np.frombuffer(data[8:], dtype=np.uint8)\n",
    "            return labels\n",
    "    \n",
    "    print(\"üîÑ Chargement des donn√©es MNIST...\")\n",
    "    \n",
    "    # Charger tous les fichiers\n",
    "    train_images = load_images('train-images-idx3-ubyte.gz')\n",
    "    train_labels = load_labels('train-labels-idx1-ubyte.gz')\n",
    "    test_images = load_images('t10k-images-idx3-ubyte.gz')\n",
    "    test_labels = load_labels('t10k-labels-idx1-ubyte.gz')\n",
    "    \n",
    "    print(f\"‚úÖ Dataset charg√©:\")\n",
    "    print(f\"   üìä Training: {train_images.shape[0]:,} images ({train_images.shape[1]}x{train_images.shape[2]})\")\n",
    "    print(f\"   üìä Test: {test_images.shape[0]:,} images ({test_images.shape[1]}x{test_images.shape[2]})\")\n",
    "    print(f\"   üìä Classes: {len(np.unique(train_labels))} (chiffres 0-9)\")\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "# Charger les donn√©es\n",
    "train_images, train_labels, test_images, test_labels = download_mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de quelques exemples avant pr√©processing\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "fig.suptitle('üìä Exemples d\\'images MNIST (avant pr√©processing)', fontsize=14, y=1.02)\n",
    "\n",
    "for i in range(10):\n",
    "    row, col = i // 5, i % 5\n",
    "    axes[row, col].imshow(train_images[i], cmap='gray')\n",
    "    axes[row, col].set_title(f'Label: {train_labels[i]}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques des donn√©es brutes\n",
    "print(\"üìà Statistiques des donn√©es brutes:\")\n",
    "print(f\"   üî¢ Valeurs pixels: [{train_images.min()}, {train_images.max()}]\")\n",
    "print(f\"   üìä Moyenne: {train_images.mean():.3f}\")\n",
    "print(f\"   üìä √âcart-type: {train_images.std():.3f}\")\n",
    "print(f\"   üìä Distribution labels: {np.bincount(train_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_onnx(model, onnx_path='models/mnist_model.onnx'):\n",
    "    \"\"\"\n",
    "    Exporte le mod√®le PyTorch vers le format ONNX\n",
    "    \n",
    "    Args:\n",
    "        model: Mod√®le PyTorch entra√Æn√©\n",
    "        onnx_path: Chemin de sauvegarde du mod√®le ONNX\n",
    "    \n",
    "    Returns:\n",
    "        bool: True si l'export a r√©ussi\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîÑ Export du mod√®le vers ONNX...\")\n",
    "    \n",
    "    # Mettre le mod√®le en mode √©valuation\n",
    "    model.eval()\n",
    "    \n",
    "    # Cr√©er un exemple d'entr√©e pour l'export\n",
    "    example_input = torch.randn(1, 1, 28, 28, dtype=torch.float32).to(device)\n",
    "    \n",
    "    try:\n",
    "        # Export ONNX avec configuration optimis√©e pour le web\n",
    "        torch.onnx.export(\n",
    "            model,                      # Mod√®le PyTorch\n",
    "            example_input,              # Exemple d'entr√©e\n",
    "            onnx_path,                  # Chemin de sortie\n",
    "            export_params=True,         # Exporter les param√®tres du mod√®le\n",
    "            opset_version=11,           # Version ONNX (compatible navigateurs)\n",
    "            do_constant_folding=True,   # Optimisation des constantes\n",
    "            input_names=['input'],      # Nom de l'entr√©e\n",
    "            output_names=['output'],    # Nom de la sortie\n",
    "            dynamic_axes={              # Dimensions dynamiques pour batch variable\n",
    "                'input': {0: 'batch_size'},\n",
    "                'output': {0: 'batch_size'}\n",
    "            },\n",
    "            verbose=False               # Pas de logs verbeux\n",
    "        )\n",
    "        \n",
    "        # V√©rification de la taille du fichier\n",
    "        if os.path.exists(onnx_path):\n",
    "            size_mb = os.path.getsize(onnx_path) / (1024 * 1024)\n",
    "            print(f\"‚úÖ Export ONNX r√©ussi!\")\n",
    "            print(f\"üìä Fichier: {onnx_path}\")\n",
    "            print(f\"üìä Taille: {size_mb:.1f} MB\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå Erreur: Fichier ONNX non cr√©√©\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors de l'export ONNX: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_onnx_inference(onnx_path, num_samples=5):\n",
    "    \"\"\"\n",
    "    Test l'inf√©rence ONNX et compare avec PyTorch\n",
    "    \n",
    "    Args:\n",
    "        onnx_path: Chemin du mod√®le ONNX\n",
    "        num_samples: Nombre d'√©chantillons √† tester\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        import onnxruntime\n",
    "        print(\"üß™ Test de l'inf√©rence ONNX...\")\n",
    "        \n",
    "        # Cr√©er la session ONNX Runtime\n",
    "        ort_session = onnxruntime.InferenceSession(\n",
    "            onnx_path,\n",
    "            providers=['CPUExecutionProvider']  # CPU uniquement pour la compatibilit√© web\n",
    "        )\n",
    "        \n",
    "        # Obtenir quelques √©chantillons du dataset de test\n",
    "        sample_data = []\n",
    "        sample_labels = []\n",
    "        \n",
    "        for i, (data, label) in enumerate(test_loader):\n",
    "            if i * BATCH_SIZE >= num_samples:\n",
    "                break\n",
    "            sample_data.append(data[:num_samples - len(sample_data)])\n",
    "            sample_labels.extend(label[:num_samples - len(sample_labels)])\n",
    "        \n",
    "        sample_data = torch.cat(sample_data)[:num_samples]\n",
    "        sample_labels = sample_labels[:num_samples]\n",
    "        \n",
    "        # Pr√©dictions PyTorch\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pytorch_outputs = model(sample_data.to(device))\n",
    "            pytorch_preds = torch.argmax(pytorch_outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        # Pr√©dictions ONNX\n",
    "        onnx_inputs = sample_data.cpu().numpy()\n",
    "        onnx_outputs = ort_session.run(None, {'input': onnx_inputs})[0]\n",
    "        onnx_preds = np.argmax(onnx_outputs, axis=1)\n",
    "        \n",
    "        # Comparaison des r√©sultats\n",
    "        matches = np.sum(pytorch_preds == onnx_preds)\n",
    "        print(f\"‚úÖ Concordance PyTorch-ONNX: {matches}/{num_samples} ({100*matches/num_samples:.1f}%)\")\n",
    "        \n",
    "        # Afficher quelques exemples\n",
    "        print(\"üîç Exemples de pr√©dictions:\")\n",
    "        for i in range(min(3, num_samples)):\n",
    "            true_label = sample_labels[i]\n",
    "            pytorch_pred = pytorch_preds[i]\n",
    "            onnx_pred = onnx_preds[i]\n",
    "            match = \"‚úÖ\" if pytorch_pred == onnx_pred else \"‚ùå\"\n",
    "            print(f\"   √âchantillon {i+1}: Vrai={true_label} | PyTorch={pytorch_pred} | ONNX={onnx_pred} {match}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"‚ö†Ô∏è onnxruntime non install√© - Test d'inf√©rence ignor√©\")\n",
    "        print(\"   Installation: pip install onnxruntime\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Erreur lors du test ONNX: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"üöÄ EXPORT ONNX\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Export du mod√®le vers ONNX\n",
    "success = export_to_onnx(model)\n",
    "\n",
    "if success:\n",
    "    # Test de l'inf√©rence ONNX\n",
    "    test_onnx_inference('models/mnist_model.onnx')\n",
    "    \n",
    "    # Copier vers le dossier web\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.copy('models/mnist_model.onnx', 'docs/mnist_model.onnx')\n",
    "        print(\"‚úÖ Mod√®le ONNX copi√© vers docs/mnist_model.onnx\")\n",
    "        print(\"üåê Pr√™t pour l'interface web!\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Erreur lors de la copie: {e}\")\n",
    "    \n",
    "    print(\"\\\\nüéâ PROJET MNIST TERMIN√â AVEC SUCC√àS!\")\n",
    "    print(\"üìÅ Fichiers g√©n√©r√©s:\")\n",
    "    print(\"   üíæ models/mnist_model_best.pth - Mod√®le PyTorch\")\n",
    "    print(\"   üåê models/mnist_model.onnx - Mod√®le ONNX\")\n",
    "    print(\"   üåê docs/mnist_model.onnx - Pr√™t pour le web\")\n",
    "else:\n",
    "    print(\"‚ùå Export ONNX √©chou√© - V√©rifiez les erreurs ci-dessus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c2b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(images, labels):\n",
    "    \"\"\"\n",
    "    Pr√©processing des donn√©es MNIST selon les standards\n",
    "    \n",
    "    Args:\n",
    "        images: numpy array de forme (N, 28, 28)\n",
    "        labels: numpy array de forme (N,)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (images_tensor, labels_tensor) normalis√©s\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Conversion en float32 et normalisation [0,255] ‚Üí [0,1]\n",
    "    images = images.astype(np.float32) / 255.0\n",
    "    \n",
    "    # 2. Standardisation MNIST (calcul√©e sur l'ensemble du dataset)\n",
    "    mean = 0.1307  # Moyenne officielle MNIST\n",
    "    std = 0.3081   # √âcart-type officiel MNIST\n",
    "    images = (images - mean) / std\n",
    "    \n",
    "    # 3. Ajouter la dimension canal: (28, 28) ‚Üí (1, 28, 28)\n",
    "    images = images[:, np.newaxis, :, :]\n",
    "    \n",
    "    # 4. Conversion en tenseurs PyTorch\n",
    "    images_tensor = torch.from_numpy(images)\n",
    "    labels_tensor = torch.from_numpy(labels.astype(np.int64))\n",
    "    \n",
    "    return images_tensor, labels_tensor\n",
    "\n",
    "def create_data_loaders(batch_size=64):\n",
    "    \"\"\"\n",
    "    Cr√©e les DataLoaders PyTorch pour l'entra√Ænement\n",
    "    \n",
    "    Args:\n",
    "        batch_size: Taille des batches\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (train_loader, test_loader)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üîÑ Pr√©processing des donn√©es...\")\n",
    "    \n",
    "    # Pr√©processing\n",
    "    train_images_tensor, train_labels_tensor = preprocess_data(train_images, train_labels)\n",
    "    test_images_tensor, test_labels_tensor = preprocess_data(test_images, test_labels)\n",
    "    \n",
    "    # Cr√©er les datasets PyTorch\n",
    "    train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "    test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "    \n",
    "    # Cr√©er les DataLoaders avec m√©lange pour l'entra√Ænement\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(f\"‚úÖ DataLoaders cr√©√©s:\")\n",
    "    print(f\"   üîÑ Training: {len(train_loader)} batches de {batch_size} images\")\n",
    "    print(f\"   üîÑ Test: {len(test_loader)} batches de {batch_size} images\")\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# Cr√©er les DataLoaders\n",
    "BATCH_SIZE = 128     \n",
    "train_loader, test_loader = create_data_loaders(BATCH_SIZE)\n",
    "\n",
    "# V√©rifier un batch d'exemple\n",
    "sample_batch = next(iter(train_loader))\n",
    "sample_images, sample_labels = sample_batch\n",
    "print(f\"\\\\nüì¶ Exemple de batch:\")\n",
    "print(f\"   üìä Images: {sample_images.shape} (batch, canal, hauteur, largeur)\")\n",
    "print(f\"   üìä Labels: {sample_labels.shape}\")\n",
    "print(f\"   üìä Plage valeurs: [{sample_images.min():.3f}, {sample_images.max():.3f}]\")\n",
    "print(f\"   üìä Labels exemple: {sample_labels[:10].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b79548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch_num):\n",
    "    \"\"\"\n",
    "    Entra√Æne le mod√®le pour une √©poque\n",
    "    \n",
    "    Args:\n",
    "        model: Mod√®le PyTorch\n",
    "        train_loader: DataLoader d'entra√Ænement\n",
    "        criterion: Fonction de perte\n",
    "        optimizer: Optimiseur\n",
    "        device: Device (cpu/cuda)\n",
    "        epoch_num: Num√©ro de l'√©poque actuelle\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (loss_moyenne, accuracy_pourcentage)\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()  # Mode entra√Ænement\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Barre de progression\n",
    "    batch_count = 0\n",
    "    print_interval = len(train_loader) // 10  # Affichage 10 fois par √©poque\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # D√©placer sur le device\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistiques\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Affichage du progr√®s\n",
    "        if batch_idx % print_interval == 0 and batch_idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            current_acc = 100. * correct / total\n",
    "            print(f'   üìä √âpoque {epoch_num} | Batch {batch_idx:3d}/{len(train_loader)} | '\n",
    "                  f'Loss: {loss.item():.4f} | Acc: {current_acc:.2f}% | '\n",
    "                  f'Temps: {elapsed:.1f}s')\n",
    "    \n",
    "    # R√©sultats finaux de l'√©poque\n",
    "    final_loss = running_loss / len(train_loader)\n",
    "    final_accuracy = 100. * correct / total\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    print(f'‚úÖ √âpoque {epoch_num} termin√©e - Loss: {final_loss:.4f} | '\n",
    "          f'Accuracy: {final_accuracy:.2f}% | Temps: {epoch_time:.1f}s')\n",
    "    \n",
    "    return final_loss, final_accuracy\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    √âvalue le mod√®le sur le dataset de test\n",
    "    \n",
    "    Args:\n",
    "        model: Mod√®le PyTorch  \n",
    "        test_loader: DataLoader de test\n",
    "        criterion: Fonction de perte\n",
    "        device: Device (cpu/cuda)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (loss_moyenne, accuracy_pourcentage)\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()  # Mode √©valuation\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Pas de gradient pour l'√©valuation\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    final_loss = test_loss / len(test_loader)\n",
    "    final_accuracy = 100. * correct / total\n",
    "    \n",
    "    return final_loss, final_accuracy\n",
    "\n",
    "def save_model(model, optimizer, epoch, loss, accuracy, filepath):\n",
    "    \"\"\"\n",
    "    Sauvegarde le mod√®le avec m√©tadonn√©es\n",
    "    \n",
    "    Args:\n",
    "        model: Mod√®le PyTorch\n",
    "        optimizer: Optimiseur\n",
    "        epoch: Num√©ro d'√©poque\n",
    "        loss: Loss actuelle\n",
    "        accuracy: Accuracy actuelle  \n",
    "        filepath: Chemin de sauvegarde\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'model_architecture': 'MNISTNet CNN'\n",
    "    }, filepath)\n",
    "    \n",
    "    print(f\"üíæ Mod√®le sauvegard√©: {filepath}\")\n",
    "\n",
    "print(\"‚úÖ Fonctions d'entra√Ænement d√©finies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31811ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam√®tres d'entra√Ænement\n",
    "NUM_EPOCHS = 10  # Augment√© pour une meilleure pr√©cision\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(\"üöÄ D√©but de l'entra√Ænement MNIST\")\n",
    "print(f\"üìä Configuration:\")\n",
    "print(f\"   üî¢ √âpoques: {NUM_EPOCHS}\")\n",
    "print(f\"   üìà Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"   üèóÔ∏è Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   üñ•Ô∏è Device: {device}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialisation du mod√®le et des composants d'entra√Ænement\n",
    "model = MNISTNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Variables pour suivre le meilleur mod√®le\n",
    "best_accuracy = 0.0\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Boucle d'entra√Ænement principale\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\\\nüîÑ === √âPOQUE {epoch}/{NUM_EPOCHS} ===\")\n",
    "    \n",
    "    # Entra√Ænement sur une √©poque\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    \n",
    "    # √âvaluation sur le dataset de test\n",
    "    print(\"üß™ √âvaluation sur le dataset de test...\")\n",
    "    test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Enregistrer les m√©triques\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    # Affichage des r√©sultats de l'√©poque\n",
    "    print(f\"üìä R√©sultats √âpoque {epoch}:\")\n",
    "    print(f\"   üèãÔ∏è Train - Loss: {train_loss:.4f} | Accuracy: {train_acc:.2f}%\")\n",
    "    print(f\"   üß™ Test  - Loss: {test_loss:.4f} | Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    # Sauvegarder le meilleur mod√®le\n",
    "    if test_acc > best_accuracy:\n",
    "        best_accuracy = test_acc\n",
    "        save_model(model, optimizer, epoch, test_loss, test_acc, 'models/mnist_model_best.pth')\n",
    "        print(f\"üèÜ Nouveau meilleur mod√®le! Accuracy: {best_accuracy:.2f}%\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Statistiques finales\n",
    "total_time = time.time() - total_start_time\n",
    "print(f\"\\\\nüéâ ENTRA√éNEMENT TERMIN√â!\")\n",
    "print(f\"‚è±Ô∏è Temps total: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "print(f\"üèÜ Meilleure accuracy: {best_accuracy:.2f}%\")\n",
    "print(f\"üìà Am√©lioration: {test_accuracies[-1] - test_accuracies[0]:.2f}% points\")\n",
    "\n",
    "# Sauvegarder le mod√®le final\n",
    "save_model(model, optimizer, NUM_EPOCHS, test_losses[-1], test_accuracies[-1], 'models/mnist_model_final.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphiques de performance\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('üìà R√©sultats d\\'entra√Ænement MNIST CNN', fontsize=16, y=0.98)\n",
    "\n",
    "epochs = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "# Graphique 1: Loss d'entra√Ænement et de test\n",
    "ax1.plot(epochs, train_losses, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "ax1.plot(epochs, test_losses, 'r-o', label='Test Loss', linewidth=2, markersize=6)\n",
    "ax1.set_title('üìâ √âvolution de la Loss', fontsize=14)\n",
    "ax1.set_xlabel('√âpoque')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 2: Accuracy d'entra√Ænement et de test\n",
    "ax2.plot(epochs, train_accuracies, 'b-o', label='Training Accuracy', linewidth=2, markersize=6)\n",
    "ax2.plot(epochs, test_accuracies, 'r-o', label='Test Accuracy', linewidth=2, markersize=6)\n",
    "ax2.set_title('üìà √âvolution de l\\'Accuracy', fontsize=14)\n",
    "ax2.set_xlabel('√âpoque')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(80, 100)  # Focus sur la plage haute\n",
    "\n",
    "# Graphique 3: Comparaison Train vs Test Accuracy\n",
    "ax3.scatter(train_accuracies, test_accuracies, c=epochs, cmap='viridis', s=100, alpha=0.7)\n",
    "ax3.plot([80, 100], [80, 100], 'k--', alpha=0.5, label='Train = Test')\n",
    "ax3.set_title('üéØ Train vs Test Accuracy', fontsize=14)\n",
    "ax3.set_xlabel('Training Accuracy (%)')\n",
    "ax3.set_ylabel('Test Accuracy (%)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_xlim(80, 100)\n",
    "ax3.set_ylim(80, 100)\n",
    "\n",
    "# Graphique 4: M√©triques finales\n",
    "metrics = ['Train Loss', 'Test Loss', 'Train Acc', 'Test Acc']\n",
    "values = [train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]]\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold']\n",
    "\n",
    "bars = ax4.bar(metrics, values, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax4.set_title('üìä M√©triques finales', fontsize=14)\n",
    "ax4.set_ylabel('Valeur')\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar, value in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{value:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# R√©sum√© statistique\n",
    "print(\"üìä R√âSUM√â DES PERFORMANCES:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"üéØ Accuracy finale: {test_accuracies[-1]:.2f}%\")\n",
    "print(f\"üèÜ Meilleure accuracy: {best_accuracy:.2f}%\")\n",
    "print(f\"üìà Am√©lioration totale: {test_accuracies[-1] - test_accuracies[0]:.2f}% points\")\n",
    "print(f\"üìâ Loss finale: {test_losses[-1]:.4f}\")\n",
    "print(f\"‚öñÔ∏è √âcart Train-Test: {abs(train_accuracies[-1] - test_accuracies[-1]):.2f}% points\")\n",
    "\n",
    "if abs(train_accuracies[-1] - test_accuracies[-1]) < 5:\n",
    "    print(\"‚úÖ Pas de surapprentissage d√©tect√©\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Possible surapprentissage\")\n",
    "\n",
    "if test_accuracies[-1] > 95:\n",
    "    print(\"üéâ Objectif de >95% atteint!\")\n",
    "else:\n",
    "    print(f\"üéØ Objectif: atteindre >95% (actuel: {test_accuracies[-1]:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b470cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import threading\n",
    "import socket\n",
    "from IPython.display import HTML, display\n",
    "import webbrowser\n",
    "\n",
    "def check_port_available(port):\n",
    "    \"\"\"V√©rifie si un port est disponible\"\"\"\n",
    "    try:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            return s.connect_ex(('localhost', port)) != 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def start_web_server(port=8000):\n",
    "    \"\"\"Lance le serveur web depuis le dossier web (chemin correct)\"\"\"\n",
    "    \n",
    "    # V√©rifier que le port est libre\n",
    "    original_port = port\n",
    "    while not check_port_available(port):\n",
    "        port += 1\n",
    "        if port > original_port + 10:\n",
    "            print(f\"‚ùå Impossible de trouver un port libre (test√© {original_port}-{port})\")\n",
    "            return None\n",
    "    \n",
    "    # V√©rifier que le dossier web et le mod√®le existent\n",
    "    web_dir = 'docs'\n",
    "    model_file = os.path.join(web_dir, 'mnist_model.onnx')\n",
    "    \n",
    "    if not os.path.exists(web_dir):\n",
    "        print(f\"‚ùå Dossier {web_dir} introuvable\")\n",
    "        return None\n",
    "        \n",
    "    if not os.path.exists(model_file):\n",
    "        print(f\"‚ùå Mod√®le ONNX introuvable: {model_file}\")\n",
    "        print(\"   Ex√©cutez d'abord la cellule d'export ONNX\")\n",
    "        return None\n",
    "    \n",
    "    def run_server():\n",
    "        try:\n",
    "            # Lancer le serveur depuis le dossier web (IMPORTANT pour les chemins relatifs)\n",
    "            subprocess.run(['python', '-m', 'http.server', str(port)],\n",
    "                         stdout=subprocess.DEVNULL,\n",
    "                         stderr=subprocess.DEVNULL,\n",
    "                         cwd=web_dir)  # Ex√©cuter depuis le dossier web\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Erreur serveur: {e}\")\n",
    "\n",
    "    server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "    server_thread.start()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # URLs corrig√©es\n",
    "    local_url = f\"http://localhost:{port}/\"  # Pas de /web/ car on lance depuis web/\n",
    "    network_url = f\"http://127.0.0.1:{port}/\"\n",
    "\n",
    "    print(\"‚úÖ Serveur web d√©marr√© avec succ√®s!\")\n",
    "    print(f\"üåê Acc√®s local: {local_url}\")\n",
    "    print(f\"üåê Acc√®s r√©seau: {network_url}\")\n",
    "    \n",
    "    # Cr√©er un lien cliquable\n",
    "    display(HTML(f'''\n",
    "    <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                padding: 20px; border-radius: 10px; text-align: center; margin: 20px 0;\">\n",
    "        <h2 style=\"color: white; margin-bottom: 15px;\">üåê Interface Web MNIST</h2>\n",
    "        <a href=\"{local_url}\" target=\"_blank\" \n",
    "           style=\"background: white; color: #667eea; padding: 15px 30px; \n",
    "                  border-radius: 25px; text-decoration: none; font-weight: bold;\n",
    "                  box-shadow: 0 4px 15px rgba(0,0,0,0.2); font-size: 18px;\">\n",
    "            üöÄ Ouvrir l'Interface MNIST\n",
    "        </a>\n",
    "        <p style=\"color: white; margin-top: 15px; font-size: 14px;\">\n",
    "            Dessinez un chiffre et obtenez une pr√©diction instantan√©e !\n",
    "        </p>\n",
    "    </div>\n",
    "    '''))\n",
    "    \n",
    "    return port\n",
    "\n",
    "print(\"üöÄ LANCEMENT DE L'INTERFACE WEB\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "server_port = start_web_server()\n",
    "\n",
    "if server_port:\n",
    "    print(f\"\\nüéâ Interface web active sur le port {server_port}\")\n",
    "    print(\"üí° Conseil: Testez diff√©rents chiffres pour voir la pr√©cision de votre mod√®le!\")\n",
    "    print(\"üéØ La pr√©diction se fait automatiquement - plus besoin de cliquer sur un bouton!\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Erreur lors du lancement de l'interface web\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
