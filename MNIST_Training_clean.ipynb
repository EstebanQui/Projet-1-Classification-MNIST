{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6794ab4",
   "metadata": {},
   "source": [
    "# MNIST Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9372de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import gzip\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# Configuration du style matplotlib\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n",
    "# Configuration PyTorch\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.manual_seed(42)  # Pour la reproductibilitÃ©\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"ğŸ”§ Configuration du systÃ¨me\")\n",
    "print(f\"âœ… Device utilisÃ©: {device}\")\n",
    "print(f\"âœ… PyTorch version: {torch.__version__}\")\n",
    "print(f\"âœ… NumPy version: {np.__version__}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"âœ… GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"âœ… CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"âœ… MÃ©moire GPU disponible: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "else:\n",
    "    print(\"âš ï¸  GPU non disponible, utilisation du CPU\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "476c61b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTNet(nn.Module):\n",
    "    \"\"\"\n",
    "    Architecture CNN pour la classification MNIST\n",
    "    \n",
    "    Structure:\n",
    "    - Conv2D(1â†’32) + ReLU + MaxPool2D\n",
    "    - Conv2D(32â†’64) + ReLU + MaxPool2D  \n",
    "    - Conv2D(64â†’128) + ReLU + MaxPool2D\n",
    "    - Flatten + FC(1152â†’512) + ReLU + Dropout(0.5)\n",
    "    - FC(512â†’256) + ReLU + Dropout(0.5)\n",
    "    - FC(256â†’10) [Sortie - 10 classes]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MNISTNet, self).__init__()\n",
    "        \n",
    "        # Couches convolutionnelles\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)    # 28x28 â†’ 28x28\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)   # 14x14 â†’ 14x14  \n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # 7x7 â†’ 7x7\n",
    "        \n",
    "        # MaxPooling 2x2\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Couches fully connected\n",
    "        # AprÃ¨s 3x MaxPool2D: 28â†’14â†’7â†’3, donc 3x3x128 = 1152\n",
    "        self.fc1 = nn.Linear(128 * 3 * 3, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)  # 10 classes (chiffres 0-9)\n",
    "        \n",
    "        # Dropout pour rÃ©gularisation\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Bloc convolutionnel 1: Conv â†’ ReLU â†’ MaxPool\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # (B, 1, 28, 28) â†’ (B, 32, 14, 14)\n",
    "        \n",
    "        # Bloc convolutionnel 2\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # (B, 32, 14, 14) â†’ (B, 64, 7, 7)\n",
    "        \n",
    "        # Bloc convolutionnel 3  \n",
    "        x = self.pool(F.relu(self.conv3(x)))  # (B, 64, 7, 7) â†’ (B, 128, 3, 3)\n",
    "        \n",
    "        # Aplatir pour les couches FC\n",
    "        x = x.view(-1, 128 * 3 * 3)  # (B, 128, 3, 3) â†’ (B, 1152)\n",
    "        \n",
    "        # Couches fully connected avec dropout\n",
    "        x = F.relu(self.fc1(x))      # (B, 1152) â†’ (B, 512)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))      # (B, 512) â†’ (B, 256)  \n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = self.fc3(x)              # (B, 256) â†’ (B, 10)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def count_parameters(self):\n",
    "        \"\"\"Compte le nombre de paramÃ¨tres du modÃ¨le\"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "# CrÃ©er une instance du modÃ¨le pour tester\n",
    "model = MNISTNet().to(device)\n",
    "print(f\"ğŸ§  ModÃ¨le CNN crÃ©Ã© avec {model.count_parameters():,} paramÃ¨tres\")\n",
    "\n",
    "# Tester avec un exemple d'entrÃ©e\n",
    "example_input = torch.randn(1, 1, 28, 28).to(device)\n",
    "with torch.no_grad():\n",
    "    example_output = model(example_input)\n",
    "    print(f\"âœ… Test forward pass: {example_input.shape} â†’ {example_output.shape}\")\n",
    "    print(f\"âœ… Exemple de sortie: {example_output.squeeze()[:5].cpu().numpy()}\")  # PremiÃ¨res 5 valeurs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326304c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_mnist():\n",
    "    \"\"\"\n",
    "    TÃ©lÃ©charge et charge les donnÃ©es MNIST depuis les serveurs PyTorch officiels\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (train_images, train_labels, test_images, test_labels)\n",
    "    \"\"\"\n",
    "    \n",
    "    # URLs des serveurs PyTorch (plus fiables que le site original)\n",
    "    urls = {\n",
    "        'train-images-idx3-ubyte.gz': 'https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz',\n",
    "        'train-labels-idx1-ubyte.gz': 'https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz',\n",
    "        't10k-images-idx3-ubyte.gz': 'https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz',\n",
    "        't10k-labels-idx1-ubyte.gz': 'https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz'\n",
    "    }\n",
    "    \n",
    "    data_dir = 'data'\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "    \n",
    "    def load_images(filename):\n",
    "        \"\"\"Charge les images depuis un fichier .gz\"\"\"\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        \n",
    "        # TÃ©lÃ©charger si nÃ©cessaire\n",
    "        if not os.path.exists(filepath):\n",
    "            url = urls[filename]\n",
    "            print(f\"ğŸ“¥ TÃ©lÃ©chargement: {filename}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"âœ… TÃ©lÃ©chargÃ©: {os.path.getsize(filepath) / 1e6:.1f} MB\")\n",
    "        \n",
    "        # Lire le fichier binaire\n",
    "        with gzip.open(filepath, 'rb') as f:\n",
    "            data = f.read()\n",
    "            magic = int.from_bytes(data[0:4], 'big')\n",
    "            num_images = int.from_bytes(data[4:8], 'big')\n",
    "            rows = int.from_bytes(data[8:12], 'big')\n",
    "            cols = int.from_bytes(data[12:16], 'big')\n",
    "            \n",
    "            images = np.frombuffer(data[16:], dtype=np.uint8)\n",
    "            images = images.reshape(num_images, rows, cols)\n",
    "            return images\n",
    "    \n",
    "    def load_labels(filename):\n",
    "        \"\"\"Charge les labels depuis un fichier .gz\"\"\"\n",
    "        filepath = os.path.join(data_dir, filename)\n",
    "        \n",
    "        # TÃ©lÃ©charger si nÃ©cessaire\n",
    "        if not os.path.exists(filepath):\n",
    "            url = urls[filename]\n",
    "            print(f\"ğŸ“¥ TÃ©lÃ©chargement: {filename}\")\n",
    "            response = requests.get(url, stream=True)\n",
    "            response.raise_for_status()\n",
    "            \n",
    "            with open(filepath, 'wb') as f:\n",
    "                for chunk in response.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "            print(f\"âœ… TÃ©lÃ©chargÃ©: {os.path.getsize(filepath) / 1e3:.1f} KB\")\n",
    "        \n",
    "        # Lire le fichier binaire\n",
    "        with gzip.open(filepath, 'rb') as f:\n",
    "            data = f.read()\n",
    "            magic = int.from_bytes(data[0:4], 'big')\n",
    "            num_labels = int.from_bytes(data[4:8], 'big')\n",
    "            labels = np.frombuffer(data[8:], dtype=np.uint8)\n",
    "            return labels\n",
    "    \n",
    "    print(\"ğŸ”„ Chargement des donnÃ©es MNIST...\")\n",
    "    \n",
    "    # Charger tous les fichiers\n",
    "    train_images = load_images('train-images-idx3-ubyte.gz')\n",
    "    train_labels = load_labels('train-labels-idx1-ubyte.gz')\n",
    "    test_images = load_images('t10k-images-idx3-ubyte.gz')\n",
    "    test_labels = load_labels('t10k-labels-idx1-ubyte.gz')\n",
    "    \n",
    "    print(f\"âœ… Dataset chargÃ©:\")\n",
    "    print(f\"   ğŸ“Š Training: {train_images.shape[0]:,} images ({train_images.shape[1]}x{train_images.shape[2]})\")\n",
    "    print(f\"   ğŸ“Š Test: {test_images.shape[0]:,} images ({test_images.shape[1]}x{test_images.shape[2]})\")\n",
    "    print(f\"   ğŸ“Š Classes: {len(np.unique(train_labels))} (chiffres 0-9)\")\n",
    "    \n",
    "    return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "# Charger les donnÃ©es\n",
    "train_images, train_labels, test_images, test_labels = download_mnist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2641d13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualisation de quelques exemples avant prÃ©processing\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 6))\n",
    "fig.suptitle('ğŸ“Š Exemples d\\'images MNIST (avant prÃ©processing)', fontsize=14, y=1.02)\n",
    "\n",
    "for i in range(10):\n",
    "    row, col = i // 5, i % 5\n",
    "    axes[row, col].imshow(train_images[i], cmap='gray')\n",
    "    axes[row, col].set_title(f'Label: {train_labels[i]}')\n",
    "    axes[row, col].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Statistiques des donnÃ©es brutes\n",
    "print(\"ğŸ“ˆ Statistiques des donnÃ©es brutes:\")\n",
    "print(f\"   ğŸ”¢ Valeurs pixels: [{train_images.min()}, {train_images.max()}]\")\n",
    "print(f\"   ğŸ“Š Moyenne: {train_images.mean():.3f}\")\n",
    "print(f\"   ğŸ“Š Ã‰cart-type: {train_images.std():.3f}\")\n",
    "print(f\"   ğŸ“Š Distribution labels: {np.bincount(train_labels)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07da63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_to_onnx(model, onnx_path='models/mnist_model.onnx'):\n",
    "    \"\"\"\n",
    "    Exporte le modÃ¨le PyTorch vers le format ONNX\n",
    "    \n",
    "    Args:\n",
    "        model: ModÃ¨le PyTorch entraÃ®nÃ©\n",
    "        onnx_path: Chemin de sauvegarde du modÃ¨le ONNX\n",
    "    \n",
    "    Returns:\n",
    "        bool: True si l'export a rÃ©ussi\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ”„ Export du modÃ¨le vers ONNX...\")\n",
    "    \n",
    "    # Mettre le modÃ¨le en mode Ã©valuation\n",
    "    model.eval()\n",
    "    \n",
    "    # CrÃ©er un exemple d'entrÃ©e pour l'export\n",
    "    example_input = torch.randn(1, 1, 28, 28, dtype=torch.float32).to(device)\n",
    "    \n",
    "    try:\n",
    "        # Export ONNX avec configuration optimisÃ©e pour le web\n",
    "        torch.onnx.export(\n",
    "            model,                      # ModÃ¨le PyTorch\n",
    "            example_input,              # Exemple d'entrÃ©e\n",
    "            onnx_path,                  # Chemin de sortie\n",
    "            export_params=True,         # Exporter les paramÃ¨tres du modÃ¨le\n",
    "            opset_version=11,           # Version ONNX (compatible navigateurs)\n",
    "            do_constant_folding=True,   # Optimisation des constantes\n",
    "            input_names=['input'],      # Nom de l'entrÃ©e\n",
    "            output_names=['output'],    # Nom de la sortie\n",
    "            dynamic_axes={              # Dimensions dynamiques pour batch variable\n",
    "                'input': {0: 'batch_size'},\n",
    "                'output': {0: 'batch_size'}\n",
    "            },\n",
    "            verbose=False               # Pas de logs verbeux\n",
    "        )\n",
    "        \n",
    "        # VÃ©rification de la taille du fichier\n",
    "        if os.path.exists(onnx_path):\n",
    "            size_mb = os.path.getsize(onnx_path) / (1024 * 1024)\n",
    "            print(f\"âœ… Export ONNX rÃ©ussi!\")\n",
    "            print(f\"ğŸ“Š Fichier: {onnx_path}\")\n",
    "            print(f\"ğŸ“Š Taille: {size_mb:.1f} MB\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"âŒ Erreur: Fichier ONNX non crÃ©Ã©\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur lors de l'export ONNX: {e}\")\n",
    "        return False\n",
    "\n",
    "def test_onnx_inference(onnx_path, num_samples=5):\n",
    "    \"\"\"\n",
    "    Test l'infÃ©rence ONNX et compare avec PyTorch\n",
    "    \n",
    "    Args:\n",
    "        onnx_path: Chemin du modÃ¨le ONNX\n",
    "        num_samples: Nombre d'Ã©chantillons Ã  tester\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        import onnxruntime\n",
    "        print(\"ğŸ§ª Test de l'infÃ©rence ONNX...\")\n",
    "        \n",
    "        # CrÃ©er la session ONNX Runtime\n",
    "        ort_session = onnxruntime.InferenceSession(\n",
    "            onnx_path,\n",
    "            providers=['CPUExecutionProvider']  # CPU uniquement pour la compatibilitÃ© web\n",
    "        )\n",
    "        \n",
    "        # Obtenir quelques Ã©chantillons du dataset de test\n",
    "        sample_data = []\n",
    "        sample_labels = []\n",
    "        \n",
    "        for i, (data, label) in enumerate(test_loader):\n",
    "            if i * BATCH_SIZE >= num_samples:\n",
    "                break\n",
    "            sample_data.append(data[:num_samples - len(sample_data)])\n",
    "            sample_labels.extend(label[:num_samples - len(sample_labels)])\n",
    "        \n",
    "        sample_data = torch.cat(sample_data)[:num_samples]\n",
    "        sample_labels = sample_labels[:num_samples]\n",
    "        \n",
    "        # PrÃ©dictions PyTorch\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            pytorch_outputs = model(sample_data.to(device))\n",
    "            pytorch_preds = torch.argmax(pytorch_outputs, dim=1).cpu().numpy()\n",
    "        \n",
    "        # PrÃ©dictions ONNX\n",
    "        onnx_inputs = sample_data.cpu().numpy()\n",
    "        onnx_outputs = ort_session.run(None, {'input': onnx_inputs})[0]\n",
    "        onnx_preds = np.argmax(onnx_outputs, axis=1)\n",
    "        \n",
    "        # Comparaison des rÃ©sultats\n",
    "        matches = np.sum(pytorch_preds == onnx_preds)\n",
    "        print(f\"âœ… Concordance PyTorch-ONNX: {matches}/{num_samples} ({100*matches/num_samples:.1f}%)\")\n",
    "        \n",
    "        # Afficher quelques exemples\n",
    "        print(\"ğŸ” Exemples de prÃ©dictions:\")\n",
    "        for i in range(min(3, num_samples)):\n",
    "            true_label = sample_labels[i]\n",
    "            pytorch_pred = pytorch_preds[i]\n",
    "            onnx_pred = onnx_preds[i]\n",
    "            match = \"âœ…\" if pytorch_pred == onnx_pred else \"âŒ\"\n",
    "            print(f\"   Ã‰chantillon {i+1}: Vrai={true_label} | PyTorch={pytorch_pred} | ONNX={onnx_pred} {match}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except ImportError:\n",
    "        print(\"âš ï¸ onnxruntime non installÃ© - Test d'infÃ©rence ignorÃ©\")\n",
    "        print(\"   Installation: pip install onnxruntime\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Erreur lors du test ONNX: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"ğŸš€ EXPORT ONNX\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Export du modÃ¨le vers ONNX\n",
    "success = export_to_onnx(model)\n",
    "\n",
    "if success:\n",
    "    # Test de l'infÃ©rence ONNX\n",
    "    test_onnx_inference('models/mnist_model.onnx')\n",
    "    \n",
    "    # Copier vers le dossier web\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.copy('models/mnist_model.onnx', 'docs/mnist_model.onnx')\n",
    "        print(\"âœ… ModÃ¨le ONNX copiÃ© vers docs/mnist_model.onnx\")\n",
    "        print(\"ğŸŒ PrÃªt pour l'interface web!\")\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Erreur lors de la copie: {e}\")\n",
    "    \n",
    "    print(\"\\\\nğŸ‰ PROJET MNIST TERMINÃ‰ AVEC SUCCÃˆS!\")\n",
    "    print(\"ğŸ“ Fichiers gÃ©nÃ©rÃ©s:\")\n",
    "    print(\"   ğŸ’¾ models/mnist_model_best.pth - ModÃ¨le PyTorch\")\n",
    "    print(\"   ğŸŒ models/mnist_model.onnx - ModÃ¨le ONNX\")\n",
    "    print(\"   ğŸŒ docs/mnist_model.onnx - PrÃªt pour le web\")\n",
    "else:\n",
    "    print(\"âŒ Export ONNX Ã©chouÃ© - VÃ©rifiez les erreurs ci-dessus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35c2b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(images, labels):\n",
    "    \"\"\"\n",
    "    PrÃ©processing des donnÃ©es MNIST selon les standards\n",
    "    \n",
    "    Args:\n",
    "        images: numpy array de forme (N, 28, 28)\n",
    "        labels: numpy array de forme (N,)\n",
    "    \n",
    "    Returns:\n",
    "        tuple: (images_tensor, labels_tensor) normalisÃ©s\n",
    "    \"\"\"\n",
    "    \n",
    "    # 1. Conversion en float32 et normalisation [0,255] â†’ [0,1]\n",
    "    images = images.astype(np.float32) / 255.0\n",
    "    \n",
    "    # 2. Standardisation MNIST (calculÃ©e sur l'ensemble du dataset)\n",
    "    mean = 0.1307  # Moyenne officielle MNIST\n",
    "    std = 0.3081   # Ã‰cart-type officiel MNIST\n",
    "    images = (images - mean) / std\n",
    "    \n",
    "    # 3. Ajouter la dimension canal: (28, 28) â†’ (1, 28, 28)\n",
    "    images = images[:, np.newaxis, :, :]\n",
    "    \n",
    "    # 4. Conversion en tenseurs PyTorch\n",
    "    images_tensor = torch.from_numpy(images)\n",
    "    labels_tensor = torch.from_numpy(labels.astype(np.int64))\n",
    "    \n",
    "    return images_tensor, labels_tensor\n",
    "\n",
    "def create_data_loaders(batch_size=64):\n",
    "    \"\"\"\n",
    "    CrÃ©e les DataLoaders PyTorch pour l'entraÃ®nement\n",
    "    \n",
    "    Args:\n",
    "        batch_size: Taille des batches\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (train_loader, test_loader)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ğŸ”„ PrÃ©processing des donnÃ©es...\")\n",
    "    \n",
    "    # PrÃ©processing\n",
    "    train_images_tensor, train_labels_tensor = preprocess_data(train_images, train_labels)\n",
    "    test_images_tensor, test_labels_tensor = preprocess_data(test_images, test_labels)\n",
    "    \n",
    "    # CrÃ©er les datasets PyTorch\n",
    "    train_dataset = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "    test_dataset = TensorDataset(test_images_tensor, test_labels_tensor)\n",
    "    \n",
    "    # CrÃ©er les DataLoaders avec mÃ©lange pour l'entraÃ®nement\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(f\"âœ… DataLoaders crÃ©Ã©s:\")\n",
    "    print(f\"   ğŸ”„ Training: {len(train_loader)} batches de {batch_size} images\")\n",
    "    print(f\"   ğŸ”„ Test: {len(test_loader)} batches de {batch_size} images\")\n",
    "    \n",
    "    return train_loader, test_loader\n",
    "\n",
    "# CrÃ©er les DataLoaders\n",
    "BATCH_SIZE = 128     \n",
    "train_loader, test_loader = create_data_loaders(BATCH_SIZE)\n",
    "\n",
    "# VÃ©rifier un batch d'exemple\n",
    "sample_batch = next(iter(train_loader))\n",
    "sample_images, sample_labels = sample_batch\n",
    "print(f\"\\\\nğŸ“¦ Exemple de batch:\")\n",
    "print(f\"   ğŸ“Š Images: {sample_images.shape} (batch, canal, hauteur, largeur)\")\n",
    "print(f\"   ğŸ“Š Labels: {sample_labels.shape}\")\n",
    "print(f\"   ğŸ“Š Plage valeurs: [{sample_images.min():.3f}, {sample_images.max():.3f}]\")\n",
    "print(f\"   ğŸ“Š Labels exemple: {sample_labels[:10].tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b79548",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, train_loader, criterion, optimizer, device, epoch_num):\n",
    "    \"\"\"\n",
    "    EntraÃ®ne le modÃ¨le pour une Ã©poque\n",
    "    \n",
    "    Args:\n",
    "        model: ModÃ¨le PyTorch\n",
    "        train_loader: DataLoader d'entraÃ®nement\n",
    "        criterion: Fonction de perte\n",
    "        optimizer: Optimiseur\n",
    "        device: Device (cpu/cuda)\n",
    "        epoch_num: NumÃ©ro de l'Ã©poque actuelle\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (loss_moyenne, accuracy_pourcentage)\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()  # Mode entraÃ®nement\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    # Barre de progression\n",
    "    batch_count = 0\n",
    "    print_interval = len(train_loader) // 10  # Affichage 10 fois par Ã©poque\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        # DÃ©placer sur le device\n",
    "        data, targets = data.to(device), targets.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Statistiques\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "        \n",
    "        # Affichage du progrÃ¨s\n",
    "        if batch_idx % print_interval == 0 and batch_idx > 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            current_acc = 100. * correct / total\n",
    "            print(f'   ğŸ“Š Ã‰poque {epoch_num} | Batch {batch_idx:3d}/{len(train_loader)} | '\n",
    "                  f'Loss: {loss.item():.4f} | Acc: {current_acc:.2f}% | '\n",
    "                  f'Temps: {elapsed:.1f}s')\n",
    "    \n",
    "    # RÃ©sultats finaux de l'Ã©poque\n",
    "    final_loss = running_loss / len(train_loader)\n",
    "    final_accuracy = 100. * correct / total\n",
    "    epoch_time = time.time() - start_time\n",
    "    \n",
    "    print(f'âœ… Ã‰poque {epoch_num} terminÃ©e - Loss: {final_loss:.4f} | '\n",
    "          f'Accuracy: {final_accuracy:.2f}% | Temps: {epoch_time:.1f}s')\n",
    "    \n",
    "    return final_loss, final_accuracy\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    \"\"\"\n",
    "    Ã‰value le modÃ¨le sur le dataset de test\n",
    "    \n",
    "    Args:\n",
    "        model: ModÃ¨le PyTorch  \n",
    "        test_loader: DataLoader de test\n",
    "        criterion: Fonction de perte\n",
    "        device: Device (cpu/cuda)\n",
    "        \n",
    "    Returns:\n",
    "        tuple: (loss_moyenne, accuracy_pourcentage)\n",
    "    \"\"\"\n",
    "    \n",
    "    model.eval()  # Mode Ã©valuation\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():  # Pas de gradient pour l'Ã©valuation\n",
    "        for data, targets in test_loader:\n",
    "            data, targets = data.to(device), targets.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, targets)\n",
    "            \n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "    \n",
    "    final_loss = test_loss / len(test_loader)\n",
    "    final_accuracy = 100. * correct / total\n",
    "    \n",
    "    return final_loss, final_accuracy\n",
    "\n",
    "def save_model(model, optimizer, epoch, loss, accuracy, filepath):\n",
    "    \"\"\"\n",
    "    Sauvegarde le modÃ¨le avec mÃ©tadonnÃ©es\n",
    "    \n",
    "    Args:\n",
    "        model: ModÃ¨le PyTorch\n",
    "        optimizer: Optimiseur\n",
    "        epoch: NumÃ©ro d'Ã©poque\n",
    "        loss: Loss actuelle\n",
    "        accuracy: Accuracy actuelle  \n",
    "        filepath: Chemin de sauvegarde\n",
    "    \"\"\"\n",
    "    \n",
    "    os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "    \n",
    "    torch.save({\n",
    "        'epoch': epoch,\n",
    "        'model_state_dict': model.state_dict(),\n",
    "        'optimizer_state_dict': optimizer.state_dict(),\n",
    "        'loss': loss,\n",
    "        'accuracy': accuracy,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'model_architecture': 'MNISTNet CNN'\n",
    "    }, filepath)\n",
    "    \n",
    "    print(f\"ğŸ’¾ ModÃ¨le sauvegardÃ©: {filepath}\")\n",
    "\n",
    "print(\"âœ… Fonctions d'entraÃ®nement dÃ©finies\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31811ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HyperparamÃ¨tres d'entraÃ®nement\n",
    "NUM_EPOCHS = 10  # AugmentÃ© pour une meilleure prÃ©cision\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "print(\"ğŸš€ DÃ©but de l'entraÃ®nement MNIST\")\n",
    "print(f\"ğŸ“Š Configuration:\")\n",
    "print(f\"   ğŸ”¢ Ã‰poques: {NUM_EPOCHS}\")\n",
    "print(f\"   ğŸ“ˆ Learning rate: {LEARNING_RATE}\")\n",
    "print(f\"   ğŸ—ï¸ Batch size: {BATCH_SIZE}\")\n",
    "print(f\"   ğŸ–¥ï¸ Device: {device}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Initialisation du modÃ¨le et des composants d'entraÃ®nement\n",
    "model = MNISTNet().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Variables pour suivre le meilleur modÃ¨le\n",
    "best_accuracy = 0.0\n",
    "train_losses = []\n",
    "train_accuracies = []\n",
    "test_losses = []\n",
    "test_accuracies = []\n",
    "\n",
    "# Boucle d'entraÃ®nement principale\n",
    "total_start_time = time.time()\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    print(f\"\\\\nğŸ”„ === Ã‰POQUE {epoch}/{NUM_EPOCHS} ===\")\n",
    "    \n",
    "    # EntraÃ®nement sur une Ã©poque\n",
    "    train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch)\n",
    "    \n",
    "    # Ã‰valuation sur le dataset de test\n",
    "    print(\"ğŸ§ª Ã‰valuation sur le dataset de test...\")\n",
    "    test_loss, test_acc = evaluate_model(model, test_loader, criterion, device)\n",
    "    \n",
    "    # Enregistrer les mÃ©triques\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_acc)\n",
    "    \n",
    "    # Affichage des rÃ©sultats de l'Ã©poque\n",
    "    print(f\"ğŸ“Š RÃ©sultats Ã‰poque {epoch}:\")\n",
    "    print(f\"   ğŸ‹ï¸ Train - Loss: {train_loss:.4f} | Accuracy: {train_acc:.2f}%\")\n",
    "    print(f\"   ğŸ§ª Test  - Loss: {test_loss:.4f} | Accuracy: {test_acc:.2f}%\")\n",
    "    \n",
    "    # Sauvegarder le meilleur modÃ¨le\n",
    "    if test_acc > best_accuracy:\n",
    "        best_accuracy = test_acc\n",
    "        save_model(model, optimizer, epoch, test_loss, test_acc, 'models/mnist_model_best.pth')\n",
    "        print(f\"ğŸ† Nouveau meilleur modÃ¨le! Accuracy: {best_accuracy:.2f}%\")\n",
    "    \n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# Statistiques finales\n",
    "total_time = time.time() - total_start_time\n",
    "print(f\"\\\\nğŸ‰ ENTRAÃNEMENT TERMINÃ‰!\")\n",
    "print(f\"â±ï¸ Temps total: {total_time:.1f}s ({total_time/60:.1f} minutes)\")\n",
    "print(f\"ğŸ† Meilleure accuracy: {best_accuracy:.2f}%\")\n",
    "print(f\"ğŸ“ˆ AmÃ©lioration: {test_accuracies[-1] - test_accuracies[0]:.2f}% points\")\n",
    "\n",
    "# Sauvegarder le modÃ¨le final\n",
    "save_model(model, optimizer, NUM_EPOCHS, test_losses[-1], test_accuracies[-1], 'models/mnist_model_final.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9833f850",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphiques de performance\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('ğŸ“ˆ RÃ©sultats d\\'entraÃ®nement MNIST CNN', fontsize=16, y=0.98)\n",
    "\n",
    "epochs = range(1, NUM_EPOCHS + 1)\n",
    "\n",
    "# Graphique 1: Loss d'entraÃ®nement et de test\n",
    "ax1.plot(epochs, train_losses, 'b-o', label='Training Loss', linewidth=2, markersize=6)\n",
    "ax1.plot(epochs, test_losses, 'r-o', label='Test Loss', linewidth=2, markersize=6)\n",
    "ax1.set_title('ğŸ“‰ Ã‰volution de la Loss', fontsize=14)\n",
    "ax1.set_xlabel('Ã‰poque')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Graphique 2: Accuracy d'entraÃ®nement et de test\n",
    "ax2.plot(epochs, train_accuracies, 'b-o', label='Training Accuracy', linewidth=2, markersize=6)\n",
    "ax2.plot(epochs, test_accuracies, 'r-o', label='Test Accuracy', linewidth=2, markersize=6)\n",
    "ax2.set_title('ğŸ“ˆ Ã‰volution de l\\'Accuracy', fontsize=14)\n",
    "ax2.set_xlabel('Ã‰poque')\n",
    "ax2.set_ylabel('Accuracy (%)')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim(80, 100)  # Focus sur la plage haute\n",
    "\n",
    "# Graphique 3: Comparaison Train vs Test Accuracy\n",
    "ax3.scatter(train_accuracies, test_accuracies, c=epochs, cmap='viridis', s=100, alpha=0.7)\n",
    "ax3.plot([80, 100], [80, 100], 'k--', alpha=0.5, label='Train = Test')\n",
    "ax3.set_title('ğŸ¯ Train vs Test Accuracy', fontsize=14)\n",
    "ax3.set_xlabel('Training Accuracy (%)')\n",
    "ax3.set_ylabel('Test Accuracy (%)')\n",
    "ax3.legend()\n",
    "ax3.grid(True, alpha=0.3)\n",
    "ax3.set_xlim(80, 100)\n",
    "ax3.set_ylim(80, 100)\n",
    "\n",
    "# Graphique 4: MÃ©triques finales\n",
    "metrics = ['Train Loss', 'Test Loss', 'Train Acc', 'Test Acc']\n",
    "values = [train_losses[-1], test_losses[-1], train_accuracies[-1], test_accuracies[-1]]\n",
    "colors = ['skyblue', 'lightcoral', 'lightgreen', 'gold']\n",
    "\n",
    "bars = ax4.bar(metrics, values, color=colors, alpha=0.8, edgecolor='black')\n",
    "ax4.set_title('ğŸ“Š MÃ©triques finales', fontsize=14)\n",
    "ax4.set_ylabel('Valeur')\n",
    "\n",
    "# Ajouter les valeurs sur les barres\n",
    "for bar, value in zip(bars, values):\n",
    "    height = bar.get_height()\n",
    "    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "             f'{value:.2f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# RÃ©sumÃ© statistique\n",
    "print(\"ğŸ“Š RÃ‰SUMÃ‰ DES PERFORMANCES:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"ğŸ¯ Accuracy finale: {test_accuracies[-1]:.2f}%\")\n",
    "print(f\"ğŸ† Meilleure accuracy: {best_accuracy:.2f}%\")\n",
    "print(f\"ğŸ“ˆ AmÃ©lioration totale: {test_accuracies[-1] - test_accuracies[0]:.2f}% points\")\n",
    "print(f\"ğŸ“‰ Loss finale: {test_losses[-1]:.4f}\")\n",
    "print(f\"âš–ï¸ Ã‰cart Train-Test: {abs(train_accuracies[-1] - test_accuracies[-1]):.2f}% points\")\n",
    "\n",
    "if abs(train_accuracies[-1] - test_accuracies[-1]) < 5:\n",
    "    print(\"âœ… Pas de surapprentissage dÃ©tectÃ©\")\n",
    "else:\n",
    "    print(\"âš ï¸ Possible surapprentissage\")\n",
    "\n",
    "if test_accuracies[-1] > 95:\n",
    "    print(\"ğŸ‰ Objectif de >95% atteint!\")\n",
    "else:\n",
    "    print(f\"ğŸ¯ Objectif: atteindre >95% (actuel: {test_accuracies[-1]:.2f}%)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b470cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import threading\n",
    "import socket\n",
    "from IPython.display import HTML, display\n",
    "import webbrowser\n",
    "\n",
    "def check_port_available(port):\n",
    "    \"\"\"VÃ©rifie si un port est disponible\"\"\"\n",
    "    try:\n",
    "        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:\n",
    "            return s.connect_ex(('localhost', port)) != 0\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "def start_web_server(port=8000):\n",
    "    \"\"\"Lance le serveur web depuis le dossier web (chemin correct)\"\"\"\n",
    "    \n",
    "    # VÃ©rifier que le port est libre\n",
    "    original_port = port\n",
    "    while not check_port_available(port):\n",
    "        port += 1\n",
    "        if port > original_port + 10:\n",
    "            print(f\"âŒ Impossible de trouver un port libre (testÃ© {original_port}-{port})\")\n",
    "            return None\n",
    "    \n",
    "    # VÃ©rifier que le dossier web et le modÃ¨le existent\n",
    "    web_dir = 'docs'\n",
    "    model_file = os.path.join(web_dir, 'mnist_model.onnx')\n",
    "    \n",
    "    if not os.path.exists(web_dir):\n",
    "        print(f\"âŒ Dossier {web_dir} introuvable\")\n",
    "        return None\n",
    "        \n",
    "    if not os.path.exists(model_file):\n",
    "        print(f\"âŒ ModÃ¨le ONNX introuvable: {model_file}\")\n",
    "        print(\"   ExÃ©cutez d'abord la cellule d'export ONNX\")\n",
    "        return None\n",
    "    \n",
    "    def run_server():\n",
    "        try:\n",
    "            # Lancer le serveur depuis le dossier web (IMPORTANT pour les chemins relatifs)\n",
    "            subprocess.run(['python', '-m', 'http.server', str(port)],\n",
    "                         stdout=subprocess.DEVNULL,\n",
    "                         stderr=subprocess.DEVNULL,\n",
    "                         cwd=web_dir)  # ExÃ©cuter depuis le dossier web\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Erreur serveur: {e}\")\n",
    "\n",
    "    server_thread = threading.Thread(target=run_server, daemon=True)\n",
    "    server_thread.start()\n",
    "    time.sleep(2)\n",
    "\n",
    "    # URLs corrigÃ©es\n",
    "    local_url = f\"http://localhost:{port}/\"  # Pas de /web/ car on lance depuis web/\n",
    "    network_url = f\"http://127.0.0.1:{port}/\"\n",
    "\n",
    "    print(\"âœ… Serveur web dÃ©marrÃ© avec succÃ¨s!\")\n",
    "    print(f\"ğŸŒ AccÃ¨s local: {local_url}\")\n",
    "    print(f\"ğŸŒ AccÃ¨s rÃ©seau: {network_url}\")\n",
    "    \n",
    "    # CrÃ©er un lien cliquable\n",
    "    display(HTML(f'''\n",
    "    <div style=\"background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); \n",
    "                padding: 20px; border-radius: 10px; text-align: center; margin: 20px 0;\">\n",
    "        <h2 style=\"color: white; margin-bottom: 15px;\">ğŸŒ Interface Web MNIST</h2>\n",
    "        <a href=\"{local_url}\" target=\"_blank\" \n",
    "           style=\"background: white; color: #667eea; padding: 15px 30px; \n",
    "                  border-radius: 25px; text-decoration: none; font-weight: bold;\n",
    "                  box-shadow: 0 4px 15px rgba(0,0,0,0.2); font-size: 18px;\">\n",
    "            ğŸš€ Ouvrir l'Interface MNIST\n",
    "        </a>\n",
    "        <p style=\"color: white; margin-top: 15px; font-size: 14px;\">\n",
    "            Dessinez un chiffre et obtenez une prÃ©diction instantanÃ©e !\n",
    "        </p>\n",
    "    </div>\n",
    "    '''))\n",
    "    \n",
    "    return port\n",
    "\n",
    "print(\"ğŸš€ LANCEMENT DE L'INTERFACE WEB\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "server_port = start_web_server()\n",
    "\n",
    "if server_port:\n",
    "    print(f\"\\nğŸ‰ Interface web active sur le port {server_port}\")\n",
    "    print(\"ğŸ’¡ Conseil: Testez diffÃ©rents chiffres pour voir la prÃ©cision de votre modÃ¨le!\")\n",
    "    print(\"ğŸ¯ La prÃ©diction se fait automatiquement - plus besoin de cliquer sur un bouton!\")\n",
    "else:\n",
    "    print(\"\\nâŒ Erreur lors du lancement de l'interface web\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
